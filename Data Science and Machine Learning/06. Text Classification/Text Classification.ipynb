{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8da85e",
   "metadata": {},
   "source": [
    "# Text Classification For Naive Bayes "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5119aa14",
   "metadata": {},
   "source": [
    "Creating a text classification model which seperates out the files on the basis of the categories of the newsgroups. For this model I am using Naive Bayes algorithm, and comparing it with inbuilt Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ca046",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc75e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180f774",
   "metadata": {},
   "source": [
    "### Collecting all the Stopwords in the English Dictionary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8011bd7a",
   "metadata": {},
   "source": [
    "Stopwords are actually the most common words in any language (like articles, prepositions, pronouns, conjunctions, etc) and does not add much information to the text. We need to remove all the stopwords from the model so that overall memory consumption of the model could become less, process faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb194d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the stopwords in the English Dictionary\n",
    "stopwords = [\"a\",\"able\",\"about\",\"above\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\n",
    "\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"after\",\"afterwards\",\"again\",\"against\",\n",
    "\"all\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"am\",\n",
    "\"amongst\",\"an\",\"and\",\"announce\",\"another\",\"any\",\"anybody\",\"anyhow\",\"anymore\",\n",
    "\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"are\",\"aren\",\"arent\",\n",
    "\"around\",\"as\",\"aside\",\"ask\",\"asking\",\"at\",\"auth\",\"available\",\"away\",\n",
    "\"b\",\"back\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\"becoming\",\"been\",\n",
    "\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"being\",\"believe\",\"below\",\n",
    "\"besides\",\"between\",\"beyond\",\"biol\",\"both\",\"brief\",\"briefly\",\"but\",\"by\",\n",
    "\"ca\",\"came\",\"can\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\n",
    "\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"could\",\"couldnt\",\"d\",\n",
    "\"did\",\"didn't\",\"different\",\"do\",\"does\",\"doesn't\",\"doing\",\"done\",\"don't\",\n",
    "\"downwards\",\"due\",\"during\",\"e\",\"each\",\"ed\",\"edu\",\"effect\",\"eg\",\n",
    "\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\n",
    "\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\n",
    "\"f\",\"far\",\"few\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\n",
    "\"follows\",\"for\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"from\",\"further\",\n",
    "\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\n",
    "\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"had\",\"happens\",\"hardly\",\"has\",\n",
    "\"have\",\"haven't\",\"having\",\"he\",\"hed\",\"hence\",\"her\",\"here\",\"hereafter\",\n",
    "\"herein\",\"heres\",\"hereupon\",\"hers\",\"herself\",\"hes\",\"hi\",\"hid\",\"him\",\n",
    "\"his\",\"hither\",\"home\",\"how\",\"howbeit\",\"however\",\"hundred\",\"i\",\"id\",\n",
    "\"if\",\"i'll\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"in\",\"inc\",\n",
    "\"index\",\"information\",\"instead\",\"into\",\"invention\",\"inward\",\"is\",\"isn't\",\"it\",\n",
    "\"it'll\",\"its\",\"itself\",\"i've\",\"j\",\"just\",\"k\",\"keepkeeps\",\"kept\",\n",
    "\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\n",
    "\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\n",
    "\"little\",\"ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"m\",\"made\",\"mainly\",\n",
    "\"makes\",\"many\",\"may\",\"maybe\",\"me\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\n",
    "\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"more\",\"moreover\",\"most\",\"mostly\",\n",
    "\"mrs\",\"much\",\"mug\",\"must\",\"my\",\"myself\",\"n\",\"na\",\"name\",\n",
    "\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\n",
    "\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"no\",\"nobody\",\"non\",\"none\",\n",
    "\"noone\",\"nor\",\"normally\",\"nos\",\"not\",\"noted\",\"nothing\",\"now\",\"nowhere\",\n",
    "\"obtain\",\"obtained\",\"obviously\",\"of\",\"off\",\"often\",\"oh\",\"ok\",\"okay\",\n",
    "\"omitted\",\"on\",\"once\",\"one\",\"ones\",\"only\",\"onto\",\"or\",\"ord\",\n",
    "\"others\",\"otherwise\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"outside\",\"over\",\n",
    "\"owing\",\"own\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\n",
    "\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\n",
    "\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\n",
    "\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"re\",\"readily\",\n",
    "\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\n",
    "\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"s\",\"said\",\"same\",\n",
    "\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\n",
    "\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"she\",\n",
    "\"she'll\",\"shes\",\"should\",\"shouldn't\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\n",
    "\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"so\",\"some\",\"somebody\",\n",
    "\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\n",
    "\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\n",
    "\"sufficiently\",\"suggest\",\"sup\",\"suret\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\n",
    "\"than\",\"thank\",\"thanks\",\"thanx\",\"that\",\"that'll\",\"thats\",\"that've\",\"the\",\n",
    "\"theirs\",\"them\",\"themselves\",\"then\",\"thence\",\"there\",\"thereafter\",\"thereby\",\"thered\",\n",
    "\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"these\",\n",
    "\"theyd\",\"they'll\",\"theyre\",\"they've\",\"think\",\"this\",\"those\",\"thou\",\"though\",\n",
    "\"thousand\",\"throug\",\"through\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"to\",\n",
    "\"too\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\n",
    "\"twice\",\"two\",\"u\",\"un\",\"under\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\n",
    "\"unto\",\"up\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\n",
    "\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"ve\",\"very\",\"via\",\n",
    "\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"was\",\"wasnt\",\"way\",\n",
    "\"wed\",\"welcome\",\"we'll\",\"went\",\"were\",\"werent\",\"we've\",\"what\",\"whatever\",\n",
    "\"whats\",\"when\",\"whence\",\"whenever\",\"where\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\n",
    "\"whereupon\",\"wherever\",\"whether\",\"which\",\"while\",\"whim\",\"whither\",\"who\",\"whod\",\n",
    "\"whole\",\"who'll\",\"whom\",\"whomever\",\"whos\",\"whose\",\"why\",\"widely\",\"willing\",\n",
    "\"with\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"would\",\"wouldnt\",\"www\",\n",
    "\"y\",\"yes\",\"yet\",\"you\",\"youd\",\"you'll\",\"your\",\"youre\",\"yours\",\n",
    "\"yourselves\",\"you've\",\"z\",\"zero\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9724f97",
   "metadata": {},
   "source": [
    "### Making Dataset for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79925b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_input = []\n",
    "output = []\n",
    "base_dir = './20_newsgroups/'\n",
    "all_categories = []\n",
    "with os.scandir(base_dir) as entries:\n",
    "    for entry in entries:\n",
    "        all_categories.append(entry.name)\n",
    "\n",
    "for category in all_categories:\n",
    "    with os.scandir(f'{base_dir}{category}/') as folder:\n",
    "        for file in folder:\n",
    "            with open(f'{base_dir}{category}/{file.name}', 'rb') as f:\n",
    "                try:\n",
    "                    myStr = f.read()\n",
    "                    myStr = myStr.decode('utf-8')\n",
    "                    myStr = myStr.replace('\\n', ' ')\n",
    "                    myStr = myStr.replace(',',' ')\n",
    "                    myStr = myStr.replace('.',' ')\n",
    "                    myStr = myStr.split()\n",
    "                    words = []\n",
    "                    for word in myStr:\n",
    "                        word = word.strip(', ')\n",
    "                        word = word.strip('\\n')\n",
    "                        if word not in stopwords:\n",
    "                            words.append(word)\n",
    "                    words_input.append(words)\n",
    "                    output.append(category)\n",
    "                except Exception as e:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6d7bf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19924\n"
     ]
    }
   ],
   "source": [
    "print(len(words_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
